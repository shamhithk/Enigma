import json

# Path to your trace file
trace_file_path = "/content/shamhiths-MacBook-Pro.local_12354.1736782630807993000.pt.trace.json"

# Function to analyze trace file for bottlenecks
def analyze_trace_file(file_path, top_n=100):
    long_duration_events = []
    try:
        with open(file_path, 'r') as file:
            trace_data = json.load(file)
            trace_events = trace_data.get("traceEvents", [])

            # Sort events by duration to find the longest ones
            long_duration_events = sorted(trace_events, key=lambda x: x.get("dur", 0), reverse=True)[:top_n]

            print(f"Top {top_n} events with the longest durations:")
            for event in long_duration_events:
                print(f"Event: {event.get('name')}, Duration: {event.get('dur')} microseconds, Timestamp: {event.get('ts')}, Category: {event.get('cat')}, Process ID: {event.get('pid')}, Thread ID: {event.get('tid')}")

    except Exception as e:
        print(f"Error processing the trace file: {e}")

# Call the function
analyze_trace_file(trace_file_path)
